# prune_training.py

import os
import torch
from torch.nn.utils import prune
from transformers import GPT2LMHeadModel

# ==== é…ç½® ====
model_path = "../python3_distillation/gpt2_student_v2"
save_path = "./gpt2_student_v2_pruned"
prune_ratio = 0.3  # å‰ªææ¯”ä¾‹ï¼ˆ30%ï¼‰

# ==== åˆ›å»ºä¿å­˜ç›®å½• ====
os.makedirs(save_path, exist_ok=True)

# ==== åŠ è½½å°æ¨¡å‹ ====
print("ğŸš€ åŠ è½½å°æ¨¡å‹ student_v2 ...")
model = GPT2LMHeadModel.from_pretrained(model_path)

'''
| éƒ¨åˆ† | å«ä¹‰ |
|------|------|
| **æ¨¡å‹ä¸­æ‰€æœ‰çš„çº¿æ€§å±‚** | æŒ‡ Transformer æ¨¡å‹ä¸­æ‰€æœ‰çš„ `torch.nn.Linear` å±‚ï¼Œåˆ†å¸ƒåœ¨ Attention æ¨¡å—å’Œ FeedForward æ¨¡å—é‡Œï¼Œè´¯ç©¿æ•´ä¸ªæ¨¡å‹çš„æ¯ä¸€å±‚ï¼ˆLayerï¼‰ã€‚ |
| **æ‰§è¡Œ** | å¯¹è¿™äº› Linear å±‚**é€ä¸ªè¿›è¡Œå¤„ç†**ã€‚ |
| **ä¸è§„åˆ™ï¼ˆUnstructuredï¼‰å‰ªæ** | å‰ªæ‰å•ä¸ªæƒé‡ï¼Œè€Œä¸æ˜¯æ•´ä¸ªç¥ç»å…ƒæˆ–é€šé“ã€‚å‰ªçš„ä½ç½®æ˜¯é›¶æ•£çš„ï¼Œæ²¡æœ‰ç»“æ„é™åˆ¶ã€‚ |
| **L1 å‰ªæ** | æŒ‰ç…§æ¯ä¸ªæƒé‡çš„**ç»å¯¹å€¼å¤§å°ï¼ˆL1èŒƒæ•°ï¼‰æ’åº**ï¼Œå‰ªæ‰ç»å¯¹å€¼æœ€å°çš„éƒ¨åˆ†ï¼Œè®¤ä¸ºå®ƒä»¬å¯¹æ¨¡å‹ä¸é‡è¦ã€‚ |
'''
# ==== å¯¹æ‰€æœ‰ Linear å±‚åº”ç”¨ L1 Unstructured å‰ªæ ====
print(f"âœ‚ï¸ å¼€å§‹å¯¹ Linear å±‚è¿›è¡Œ L1 å‰ªæï¼Œå‰ªææ¯”ä¾‹: {prune_ratio}")
for name, module in model.named_modules():
    if isinstance(module, torch.nn.Linear):
        prune.l1_unstructured(module, name="weight", amount=prune_ratio)  # æ¯æ¬¡æ“ä½œéƒ½ä¹˜ä»¥æƒé‡
        # ä¹Ÿå¯ä»¥é€‰æ‹©ä¸ä¿ç•™maskï¼Œæ°¸ä¹…å‰ªæ‰
        prune.remove(module, "weight") # æŠŠå¯¹åº”çš„é‚£ä¸ªæ•°ç›´æ¥å†™ä¸º 0ï¼Œä»¥åä¹Ÿä¸ç”¨ä¹˜æƒé‡äº†ï¼Œæ°¸ä¹…æ”¹å†™ï¼Œå½»åº•ç˜¦èº«

print("âœ… å‰ªæå®Œæˆ")

# ==== ä¿å­˜å‰ªæåæ¨¡å‹ ====
print(f"ğŸ’¾ ä¿å­˜å‰ªæåæ¨¡å‹åˆ°: {save_path}")
model.save_pretrained(save_path)

print("ğŸ å‰ªææµç¨‹ç»“æŸï¼")
